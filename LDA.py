import numpy as np


class LDA:
    def __init__(self, X, y):
        self.X = X              # Matrix of the form (number of samples, number of predictors)
        self.y = y              # Array of the form (number of samples, )
        self.n = X.shape[0]     # Number of samples
        self.p = X.shape[1]     # Number of predictors

        self.k = 0              # Number of classes
        for i in y:
            if i > self.k:
                self.k = i
        self.k += 1

        self.counts = np.zeros(self.k)       # An array that counts how many training instances there are for each class
        for i in y:
            self.counts[i] += 1

        self.priorProbs = np.zeros(self.k)              # An array with the prior probability of each class
        self.means = np.zeros((self.k, self.p))         # An array for the approximated means for each class
        self.covariance = np.zeros((self.p, self.p))    # Approximated variance for all classes
        self.approx_mean()
        self.approx_cov()
        self.approx_class_prob()

    def approx_mean(self):
        """For each class K predict the mean and store it"""

        for i in range(self.n):
            self.means[self.y[i]:self.y[i] + 1] += self.X[i:i + 1]

        for k in range(self.k):
            self.means[k] = np.multiply((1 / self.counts[k]), self.means[k])

    def approx_cov(self):
        """Generate a prediction of the covariance"""

        for k in range(self.k):
            for i in range(self.n):
                if self.y[i] == k:
                    a = np.transpose(self.X[i:] - self.means[k])
                    b = (self.X[i:] - self.means[k])
                    x = np.matmul(a, b)
                    self.covariance += x

        self.covariance = np.multiply((1 / (self.n - self.k)), self.covariance)

    def approx_class_prob(self):
        """Generate prior probabilities for each of the K classes"""
        for k in range(self.k):
            self.priorProbs[k] = self.counts[k] / self.n

    def discriminant(self, x, k):
        """Discriminant function that returns the confidence in a class K for input X"""
        x = np.matmul(np.matmul(x, np.linalg.inv(self.covariance)), np.transpose(self.means[k]))
        y = np.matmul(np.matmul(np.multiply(-0.5, self.means[k]), np.linalg.inv(self.covariance)),
                      np.transpose(self.means[k]))
        z = np.log(self.priorProbs[k])
        return x + y + z

    def classify(self, x):
        """Classifies the input X as K based the highest value generated by the discriminant function for each K"""

        prediction = 0
        confidence = self.discriminant(x, 0)

        for k in range(1, self.k):
            newConfidence = self.discriminant(x, k)
            if newConfidence >= confidence:
                prediction = k
                confidence = newConfidence

        return prediction


def error(lda, X, y):
    num_correct = 0
    for i in range(X.shape[0]):
        pred = lda.classify(X[i:i+1])
        if pred == y[i]:
            num_correct += 1
    return ((X.shape[0] - num_correct)/X.shape[0])*100

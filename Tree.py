import numpy as np
import math


class Node:

    def __init__(self, parent=None, direction=None):
        # Tree information
        self.dir = direction    # Is it a left node (FALSE), a right node (TRUE), or a root (NONE)
        self.parent = parent    # Parent node. NONE if the node is the root of the tree
        self.right = None       # Right node if j<s
        self.left = None        # Left node if s<j

        # Node information
        self.s = None           # Decision value s
        self.j = None           # Attribute j that decision is made on
        self.error = None       # RSS value for space generated by node (None if root or terminal node)
        self.diff = None        # The difference in RSS between this node and the parent (None if root or terminal node)
        self.pred = None        # Prediction of the class or regression, if the node is not terminal then (None)


def print_tree(node, file=None, _prefix="", _last=True):
    """Method that print the tree in a ~kinda~ nice format"""

    if node.right is None and node.left is None:
        val = "pred = " + str(node.pred)
    else:
        val = str(node.s) + ' > ' + str(node.j)
    print(_prefix, "`- " if _last else "|- ", val, sep="", file=file)
    _prefix += "   " if _last else "|  "
    child_count = 2
    if node.right is None and node.left is None:
        return
    else:
        for i, child in enumerate([node.left, node.right]):
            _last = i == (child_count - 1)
            print_tree(child, file, _prefix, _last)


class DecisionTree:

    def __init__(self, xy, m, d, folds):

        # Data Info
        self.xy = xy                # Mat[number of samples, number of predictors + 1]
        self.n = xy.shape[0]        # Number of samples
        self.p = xy.shape[1] - 1    # Number of parameters

        self.minRegion = m          # Stopping condition (to not split again) if region has less than m observations
        self.maxDepth = d           # Maximum depth of the tree (default = 20)
        self.kfolds = folds         # The number of folds to create for cross validation
        self.root = Node()          # Root node for the decision tree (default = 5)
        self.subTreeSeq = []        # Array to store the sequence of subtrees from T_0 to the just the root

        self.build_tree()

    @staticmethod
    def get_unique(rj, j):
        """Find list of unique points for the Pth parameter from all the observed values and return the list"""

        values = [rj[0, j]]

        # Loop through all observed values
        for n in range(1, rj.shape[0] - 1):

            unique = True  # Value is unique unless if occurs in the list of unique values

            # Loop through current unique values
            for i in range(len(values)):

                # Find if Rj[n,j] is in the list of unique values
                if values[i] == rj[n, j]:
                    unique = False
                    break

            # If the value is unique append it to the list
            if unique:
                values.append(rj[n, j])

        return values

    @staticmethod
    def split(space, j, s):
        """Splits the observed training data into two sets based on for
           an observation X_i if its jth value is greater than s or not"""

        r1, r2 = [], []  # arrays to store two sets of data from the split

        # Loop through observations in the parent region
        for i in range(space.shape[0]):

            # If condition is met, add to r1
            if space[i, j] < s:
                if len(r1) == 0:
                    r1 = [space[i, :]]
                else:
                    r1 = np.concatenate((r1, [space[i, :]]), 0)

            # If condition fails, add to r2
            else:
                if len(r2) == 0:
                    r2 = [space[i, :]]
                else:
                    r2 = np.concatenate((r2, [space[i, :]]), 0)

        return np.array(r1), np.array(r2)

    def best_split(self, space):
        """Return the best split point given the parent region"""

    def recursive_split(self, node, previous_split, depth):
        """main recursive func"""

    def build_tree(self):
        """Construct the decision or recursion tree"""
        # Split the whole data set
        first_split = self.best_split(self.xy)

        # Create root and recurse on root and two partitions
        self.root = Node()
        self.recursive_split(self.root, first_split, 1)

    def get_node_obs(self, node):
        """Return the group of observations that fall into this node of the decision tree"""

        node_obs = self.xy  # Copy of the full data set

        # While the node has a parent make splits based on the nodes until the parents is reached
        while node.parent is not None:

            # Split the space into two subspaces based on the
            r1, r2 = self.split(node_obs, node.parent.j, node.parent.s)

            if node.dir:
                node_obs = r1
            else:
                node_obs = r2

        return node_obs

    def get_kth_fold(self, k):
        """Return numpy matrix with splits into k different folds"""

        fold_size = int(self.n / self.kfolds)  # Compute the number of observations in a fold

        # Return fold
        if k == self.kfolds - 1:
            return self.xy[k:, :]  # Full size fold
        else:
            return self.xy[k:k + fold_size, :]  # Whatever is left over at the end of the list

    def get_subtree(self, full_tree, alpha):
        """Return the subtree associated with the the value of alpha"""

        # Set previous tree to full tree and next tree to that tree with one cost complexity cut made
        prev_tree = full_tree
        next_tree = self.prune(full_tree)

        # Get the cost complexity error for each tree which factors
        # in both the error and the size of the tree as an error
        current_cost = self.cost_complexity(full_tree, alpha)
        next_cost = self.cost_complexity(next_tree, alpha)

        # Keep pruning if the next prune results in a lower error
        while next_cost < current_cost:

            # Update trees: next tree becomes the previous and the previous gets pruned again
            prev_tree = next_tree
            next_tree = self.prune(prev_tree)

            # Compute costs: next cost becomes the previous cost and the previous gets updated
            current_cost = next_cost
            next_cost = self.cost_complexity(next_tree)

        return prev_tree

    def prune(self, tree):
        """Prune the weakest link in the tree and return the new tree"""

        while tree.left is not None and tree.right is not None:
            self.prune_helper(tree)

    def prune_helper(self, tree):
        """Recursive part of the prune method"""

    def num_nodes(self, node):
        """Returns the number of nodes in a tree given by the root: node"""
        if node.left is None and node.right is None:
            return 1
        else:
            return self.num_nodes(node.left) + self.num_nodes(node.right)

    def cost_complexity(self, node, alpha):
        """Return the cost complexity function associated with the current tree, and alpha"""
        return self.sum_error(node) + alpha * self.num_nodes(node)

    def sum_error(self, node):
        """Sum of all the errors from each terminal node"""

        if node.left is None and node.right is None:
            return node.error
        else:
            return self.sum_error(node.left) + self.sum_error(node.right)

    @staticmethod
    def build_sequence(subtree):
        """Populate self.subTreeSeq with sequence of subtrees from T_0 to the just the root"""
        # If the node is terminal look to its parent and see cutdown the observation space based on the conditions
        if subtree.left is None and subtree.right is None:
            r = subtree.parent.r
            s = subtree.parent.s


class RegressionTree(DecisionTree):

    def best_split(self, space):
        """Return the best split point given the parent region"""

        j = math.inf  # What class are we splitting on
        s = math.inf  # What value to split with
        rss = math.inf  # Error value associated with the split
        r1 = None  # Space generated by j<s:
        r2 = None  # Space generated by j>=s

        # Loop through all parameters p
        for curr_j in range(self.p):

            unique = self.get_unique(space, curr_j)

            # Loop through all the unique parameters s
            for curr_s in unique:

                curr_r1, curr_r2 = self.split(space, curr_j, curr_s)  # Get spaces generated by the split
                cur_rss = self.rss(curr_r1) + self.rss(curr_r2)  # Generated the RSS based on those spaces

                # If j and s yields a lower RSS save them and the info associated with it
                if cur_rss < rss:
                    j, s, rss, r1, r2 = curr_j, curr_s, cur_rss, curr_r1, curr_r2

        return {'j': j, 's': s, 'rss': rss, 'r1': r1, 'r2': r2, 'space': space}

    # Create child splits for a node or make terminal
    def recursive_split(self, node, previous_split, depth):
        """main recursive func"""

        r1, r2, space = previous_split['r1'], previous_split['r2'], previous_split['space']

        # If one or both nodes are empty there is no need for a new children nodes
        if r1.shape[0] == 0 and r2.shape[0] == 0:
            node.dir = None
            node.pred = None
            return
        if r1.shape[0] == 0 and r2.shape[0] != 0:
            node.dir = None
            node.pred = self.mean(space)
            return
        if r1.shape[0] != 0 and r2.shape[0] == 0:
            node.dir = None
            node.pred = self.mean(space)
            return

        # There is need for new children nodes
        # Make new nodes to recurse on
        right = Node(node, True)
        left = Node(node, False)

        # Update values about the parent node
        node.j, node.s, node.error = previous_split['j'], previous_split['s'], previous_split['rss']
        node.diff = node.error - (self.rss(r1) + self.rss(r2))
        node.right, node.left = right, left

        # check for max depth
        if depth >= self.maxDepth:
            left.pred, right.pred = self.mean(r1), self.mean(r2)
            return

        # process left child
        if r1.shape[0] <= self.minRegion:
            left.pred = self.mean(r1)

        else:
            new_split = self.best_split(r1)
            self.recursive_split(left, new_split, depth + 1)

        # process right child
        if r2.shape[0] <= self.minRegion:
            right.pred = self.mean(r2)

        else:
            new_split = self.best_split(r2)
            self.recursive_split(right, new_split, depth + 1)

    def rss(self, r):
        """Returns the sum of the residual sum of squares"""

        y_hat = self.mean(r)  # Mean of the observations in r
        rss = 0  # residual sum of squares

        # for each observation in r add the squared sum
        for i in range(r.shape[0]):
            rss += (r[i, self.p] - y_hat) ** 2

        return rss

    def mean(self, r):
        """Returns the mean of y_is in this region"""

        sum_yi = 0

        if r.shape[0] == 0:
            return math.inf

        # Loop through all observations in R
        for i in range(r.shape[0]):
            sum_yi += r[i, self.p]  # Add y_i

        return sum_yi / r.shape[0]


class ClassificationTree(DecisionTree):

    def __init__(self, xy, m, d, folds):

        # Data Info
        self.xy = xy                # Mat[number of samples, number of predictors + 1]
        self.n = xy.shape[0]        # Number of samples
        self.p = xy.shape[1] - 1    # Number of parameters
        self.k = 0                  # Number of classes
        for i in xy[:, self.p]:
            if i > self.k:
                self.k = int(i)
        self.k += 1

        self.minRegion = m          # Stopping condition (to not split again) if region has less than m observations
        self.maxDepth = d           # Maximum depth of the tree (default = 20)
        self.kfolds = folds         # The number of folds to create for cross validation
        self.root = Node()          # Root node for the decision tree (default = 5)
        self.subTreeSeq = []        # Array to store the sequence of subtrees from T_0 to the just the root

        self.build_tree()


    def best_split(self, space):
        """Return the best split point given the parent region"""

        j = math.inf        # What class are we splitting on
        s = math.inf        # What value to split with
        error = math.inf    # Error value associated with the split
        r1 = None           # Space generated by j<s:
        r2 = None           # Space generated by j>=s

        # Loop through all parameters p
        for curr_j in range(self.p):

            unique = self.get_unique(space, curr_j)

            # Loop through all the unique parameters s
            for curr_s in unique:

                curr_r1, curr_r2 = self.split(space, curr_j, curr_s)  # Get spaces generated by the split
                curr_error = self.gini(curr_r1) + self.gini(curr_r2)  # Generated the Gini based on those spaces

                # If j and s yields a lower error save them and the info associated with it
                if curr_error < error:
                    j, s, error, r1, r2 = curr_j, curr_s, curr_error, curr_r1, curr_r2

        return {'j': j, 's': s, 'gini': error, 'r1': r1, 'r2': r2, 'space': space}

    def recursive_split(self, node, previous_split, depth):
        """main recursive func: Create child splits for a node or make terminal"""

        r1, r2, space = previous_split['r1'], previous_split['r2'], previous_split['space']

        # If one or both nodes are empty there is no need for a new children nodes
        if r1.shape[0] == 0 and r2.shape[0] == 0:
            node.dir = None
            node.pred = None
            return
        if r1.shape[0] == 0 and r2.shape[0] != 0:
            node.dir = None
            node.pred = self.mode(space)
            return
        if r1.shape[0] != 0 and r2.shape[0] == 0:
            node.dir = None
            node.pred = self.mode(space)
            return

        # There is need for new children nodes
        # Make new nodes to recurse on
        right = Node(node, True)
        left = Node(node, False)

        # Update values about the parent node
        node.j, node.s, node.error = previous_split['j'], previous_split['s'], previous_split['gini']
        node.right, node.left = right, left

        # check for max depth
        if depth >= self.maxDepth:
            left.pred, right.pred = self.mode(r1), self.mode(r2)
            return

        # process left child
        if r1.shape[0] <= self.minRegion:
            left.pred = self.mode(r1)

        else:
            new_split = self.best_split(r1)
            self.recursive_split(left, new_split, depth + 1)

        # process right child
        if r2.shape[0] <= self.minRegion:
            right.pred = self.mode(r2)

        else:
            new_split = self.best_split(r2)
            self.recursive_split(right, new_split, depth + 1)

    def gini(self, r):
        """Compute and return the the Gini index for a measure of node purity"""

        gini = 0

        # Go though all the k values
        for k in range(self.k):
            pmk = self.pmk(r, k)
            gini += pmk*(1-pmk)

        return gini

    def entropy(self, r):
        """Compute and return the the entropy for a measure of node purity"""

        entropy = 0

        # Go though all the k values
        for k in range(self.k):
            pmk = self.pmk(r, k)
            entropy += pmk * math.log10(pmk)

        return -entropy

    def pmk(self, r, k):
        """Returns the proportion of observations in the region r that belong to the kth class"""

        if r.shape[0] == 0:
            return 0

        count = 0          # Number of occurrences of the kth class

        # Loop through all observations in R
        for i in range(r.shape[0]):
            if r[i, self.p] == k:
                count += 1   # Increase the count for the observed class

        return count/r.shape[0]

    def mode(self, r):
        """Returns the most occurring class in this space"""

        # Initialize mode and pmk to values that will get replaced in the comparison
        mode = 0
        pmk = - math.inf

        # For each k looks that the proportion of occurrences in the current
        # space and the k that produces the largest proportion is the mode
        for k in range(self.k):
            new_pmk = self.pmk(r, k)
            if new_pmk > pmk:
                pmk = new_pmk
                mode = k

        return mode
